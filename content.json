{"pages":[],"posts":[{"title":"小熊猫来到世界","text":"","link":"/2018/06/21/小熊猫来到世界/"},{"title":"微信小程序中绘制雷达图","text":"前言雷达图（Radar Chart），又可称为戴布拉图、蜘蛛网图（Spider Chart），是财务分析报表的一种。使用者能一目了然的了解各项指标的变动情形及其好坏趋向。本文介绍如何在微信小程序中实现雷达图绘制。 绘制背景首先我们需要绘制出雷达图后面的“蜘蛛网”。具体原理就是一层一层将多边形画出来，根据数据长度决定每一个点的位置和半径长度。 123456789101112131415161718192021var angle = Math.PI * 2 / length;for (var layer = 5; layer &gt; 0; layer--) { context.beginPath(); context.setGlobalAlpha(1); context.setStrokeStyle(&quot;#D3D3D3&quot;); if (layer % 2 != 0) { context.setFillStyle(&quot;white&quot;); } else { context.setFillStyle(&quot;#F5F5F5&quot;); } var currentRad = layer / 5 * radius; context.moveTo(center.x, center.y - currentRad); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { context.lineTo(center.x + currentRad * Math.cos(currentAngle), center.y + currentRad * Math.sin(currentAngle)); currentAngle += angle; } context.fill(); context.closePath(); context.stroke(); } 如代码所示，angle是根据数据长度决定的，这里为了好看，一共画五层，并且交替涂抹颜色。下图是length=6的效果： 绘制轴接下来就是将各个顶点与圆心连接起来。有了“蜘蛛网”的经验，画轴就简单多了，只需要知道最外层顶点位置然后lineTo圆心就行了。 12345678910// draw Axiscontext.beginPath();var currentAngle = -Math.PI / 2;for (var i = 0; i &lt; length; i++) { context.moveTo(center.x + radius * Math.cos(currentAngle), center.y + radius * Math.sin(currentAngle)); context.lineTo(center.x, center.y); currentAngle += angle;}context.closePath();context.stroke(); 以下是加上轴线后的效果： 绘制指标接下来是将各个维度指标名字添加到图表上。同数轴一样，首先需要确定最外层顶点的位置，然后根据位置调整文字显示的基准，将文字写上去。 12345678910111213141516// draw Indexcontext.beginPath();context.setFillStyle(&quot;#D3D3D3&quot;);context.setFontSize(14);var currentAngle = -Math.PI / 2;for (var i = 0; i &lt; length; i++) { var posX = center.x + radius * Math.cos(currentAngle); var posY = center.y + radius * Math.sin(currentAngle); if (posX &lt; center.x) context.setTextAlign(&quot;right&quot;); else context.setTextAlign(&quot;left&quot;); if (posY &gt; center.y) context.setTextBaseline(&quot;top&quot;); else context.setTextBaseline(&quot;bottom&quot;); context.fillText(that.options.xLabel[i], posX, posY); currentAngle += angle;}context.closePath(); 这里为了好看，对于文字要显示的位置小于中心点 x 坐标的靠右对齐，否则靠左对齐；对于文字位置大于中心点 y 坐标的基准设置在上方，否则在下方。以下是加上指标后的效果： 绘制数据最后，我们将数据绘制到图表上。首先，我们要确定所有数据的最大值，如果最大值大于 10，那么取 10 的倍数。然后同画“蜘蛛网”一样，将各个数据点的半径根据相对于最大值比例换算出来，然后绘制在图表上。 1234567891011121314151617181920212223242526272829303132// draw datavar MaxValue = Math.max.apply(null, that.options.data[0].value);that.options.data.forEach(function(val) { var temp = Math.max.apply(null, val.value); if (temp &gt; MaxValue) MaxValue = temp;});if (MaxValue &gt; 10) { MaxValue = Math.ceil(MaxValue / 10) * 10}that.options.data.forEach(function(val) { context.beginPath(); context.setStrokeStyle(val.color); var currentRad = radius * val.value[0] / MaxValue * step / MaxStep; context.moveTo(center.x, center.y - currentRad); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { currentRad = radius * val.value[i] / MaxValue * step / MaxStep; context.lineTo(center.x + currentRad * Math.cos(currentAngle), center.y + currentRad * Math.sin(currentAngle)); currentAngle += angle; } currentRad = radius * val.value[0] / MaxValue * step / MaxStep; context.lineTo(center.x, center.y - currentRad); context.stroke(); if (that.options.area) { context.setFillStyle(val.color); context.setGlobalAlpha(0.5); context.fill(); } context.closePath();});context.draw(); 以下就是添加数据后的完整效果： 添加绘制动画为了显示效果更佳，我们可以给绘制图表加上动画，具体实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394var angle = Math.PI * 2 / length;var step = 1;var MaxStep = that.options.animation ? 50 : 1;var animation = function() { if (step &lt;= MaxStep) { // draw background for (var layer = 5; layer &gt; 0; layer--) { context.beginPath(); context.setGlobalAlpha(1); context.setStrokeStyle(&quot;#D3D3D3&quot;); if (layer % 2 != 0) { context.setFillStyle(&quot;white&quot;); } else { context.setFillStyle(&quot;#F5F5F5&quot;); } var currentRad = layer / 5 * radius; context.moveTo(center.x, center.y - currentRad); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { context.lineTo(center.x + currentRad * Math.cos(currentAngle), center.y + currentRad * Math.sin(currentAngle)); currentAngle += angle; } context.fill(); context.closePath(); context.stroke(); } // draw Axis context.beginPath(); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { context.moveTo(center.x + radius * Math.cos(currentAngle), center.y + radius * Math.sin(currentAngle)); context.lineTo(center.x, center.y); currentAngle += angle; } context.closePath(); context.stroke(); // draw Index context.beginPath(); context.setFillStyle(&quot;#D3D3D3&quot;); context.setFontSize(14); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { var posX = center.x + radius * Math.cos(currentAngle); var posY = center.y + radius * Math.sin(currentAngle); if (posX &lt; center.x) context.setTextAlign(&quot;right&quot;); else context.setTextAlign(&quot;left&quot;); if (posY &gt; center.y) context.setTextBaseline(&quot;top&quot;); else context.setTextBaseline(&quot;bottom&quot;); context.fillText(that.options.xLabel[i], posX, posY); currentAngle += angle; } context.closePath(); // draw data var MaxValue = Math.max.apply(null, that.options.data[0].value); that.options.data.forEach(function(val) { var temp = Math.max.apply(null, val.value); if (temp &gt; MaxValue) MaxValue = temp; }); if (MaxValue &gt; 10) { MaxValue = Math.ceil(MaxValue / 10) * 10 } that.options.data.forEach(function(val) { context.beginPath(); context.setStrokeStyle(val.color); var currentRad = radius * val.value[0] / MaxValue * step / MaxStep; context.moveTo(center.x, center.y - currentRad); var currentAngle = -Math.PI / 2; for (var i = 0; i &lt; length; i++) { currentRad = radius * val.value[i] / MaxValue * step / MaxStep; context.lineTo(center.x + currentRad * Math.cos(currentAngle), center.y + currentRad * Math.sin(currentAngle)); currentAngle += angle; } currentRad = radius * val.value[0] / MaxValue * step / MaxStep; context.lineTo(center.x, center.y - currentRad); context.stroke(); if (that.options.area) { context.setFillStyle(val.color); context.setGlobalAlpha(0.5); context.fill(); } context.closePath(); }); context.draw(); step++; } else { clearInterval(aniName); }}var aniName = setInterval(animation, 10); 最终效果如下： 结语😊 以上就是在微信小程序中绘制雷达图的方法。如有兴趣了解更多，可以查看完整代码：https://github.com/chmini-app/CHCharts-wechat。","link":"/2018/08/29/微信小程序中绘制雷达图/"},{"title":"iOS实现类Prisma软件","text":"前言 Prisma 在 2016 上线后就大火，该 APP 是利用神经网络和人工智能技术，为普通照片加入艺术效果的照片编辑软件。 同年 Google 也发布了一篇《A LEARNED REPRESENTATION FOR ARTISTIC STYLE》论文，实现了前向运算一次为照片整合多种艺术风格的功能，并且优化了内存使用和运算速度，可以在移动设备上快速运算。 最近在研究 Tensorflow 整合 iOS 过程中，发现 google 公开了论文实现的源码和训练数据，也就是说我们可以通过自己写一个前向运算图，整合其训练参数就可以快速实现类 Prisma 的应用。 下面就介绍一下如何在 iPhone 上跑一个自己的“Prisma”。 准备工作 安装Tensorflow，这个官网上有详细教程这里就不多说了。 搭建iOS+Tensorflow工程，这个可以根据 Git 上的步骤实现，也可以参考官方的 Demo 程序配置。（这个过程有很多坑，多次尝试，应该可以配置成功） 下载模型，本次使用的模型是image_stylization，google 已开源在 GitHub 上。 下载训练好的参数，Google 提供了 2 个：MonetVariedMonet 训练了 10 种艺术图片，Varied 训练了 32 种。当然你也可以自己训练艺术图片，但是得下载 VGG 的训练参数和 ImageNet 数据，然后自己训练，比较花时间。 构建计算图 虽然 Google 提供了模型的源码，但是并没有在源码中输出运算图已方便迁移到移动设备中使用，Android 的 Demo 中倒是提供了生成的 pb，如何觉得自己写计算图麻烦可以直接拷到自己 iOS 工程中使用。 我这里创建了一个 python 的工程，然后把 Google 源码中 model.py 相关的文件都加入了工程。我的建图代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import numpy as npimport tensorflow as tfimport astimport osfrom tensorflow.python import pywrap_tensorflowfrom matplotlib import pyplotfrom matplotlib.pyplot import imshowimport image_utilsimport modelimport opsimport argparseimport sysnum_styles = 32imgWidth = 512imgHeight = 512channel = 3checkpoint = &quot;/Users/Jiao/Desktop/TFProject/style-image/checkpoint/multistyle-pastiche-generator-varied.ckpt&quot;inputImage = tf.placeholder(tf.float32,shape=[None,imgWidth,imgHeight,channel],name=&quot;input&quot;)styles = tf.placeholder(tf.float32,shape=[num_styles],name=&quot;style&quot;)with tf.name_scope(&quot;&quot;): transform = model.transform(inputImage, normalizer_fn=ops.weighted_instance_norm, normalizer_params={ # &apos;weights&apos;: tf.constant(mixture), &apos;weights&apos; : styles, &apos;num_categories&apos;: num_styles, &apos;center&apos;: True, &apos;scale&apos;: True})model_saver = tf.train.Saver(tf.global_variables())with tf.Session() as sess: tf.train.write_graph(sess.graph_def, &quot;/Users/Jiao/Desktop/TFProject/style-image/protobuf&quot;, &quot;input.pb&quot;) #checkpoint = os.path.expanduser(checkpoint) #if tf.gfile.IsDirectory(checkpoint): # checkpoint = tf.train.latest_checkpoint(checkpoint) # tf.logging.info(&apos;loading latest checkpoint file: {}&apos;.format(checkpoint)) #model_saver.restore(sess, checkpoint) #newstyle = np.zeros([num_styles], dtype=np.float32) #newstyle[18] = 0.5 #newstyle[17] = 0.5 #newImage = np.zeros((1,imgWidth,imgHeight,channel)) #style_image = transform.eval(feed_dict={inputImage:newImage,styles:newstyle}) #style_image = style_image[0] #imshow(style_image) #pyplot.show() 这里输入节点是input和style，输出节点是 model 中的transformer/expand/conv3/conv/Sigmoid。 到此就将模型的计算图保存到了本地文件夹中。接下来就是将图和 ckpt 中的参数合并，并且生成移动端的可以使用的 pb 文件，这一步可以参考我上一篇文章《iOS+Tensorflow 实现图像识别》，很容易就实现。 iOS 工程 在上面准备工作中，如果你已经按步骤搭建好 iOS+TF 的工程，这里你只需要导入生成的最终 pb 文件就行了。工程结构如图： 然后在 iOS 使用 pb 文件，我这里直接导入了 Google 提供的tensorflow_utils，使用这个类里面的 LoadModel 方法可以很快的生成含有计算图的 session。 1234567891011121314- (void)viewDidLoad { [super viewDidLoad]; tensorflow::Status load_status; load_status = LoadModel(@&quot;rounded_graph&quot;, @&quot;pb&quot;, &amp;tf_session); if (!load_status.ok()) { LOG(FATAL) &lt;&lt; &quot;Couldn&apos;t load model: &quot; &lt;&lt; load_status; } currentStyle = 0; isDone = true; _styleImageView.layer.borderColor = [UIColor grayColor].CGColor; _styleImageView.layer.borderWidth = 0.5; _ogImageView.layer.borderColor = [UIColor grayColor].CGColor; _ogImageView.layer.borderWidth = 0.5;} 最后就是获取图片，执行运算，生成艺术图片展示。这里图片需要转换成 bitmap 然后获取 data 值，展示图片也是相识的过程。具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111- (void)runCnn:(UIImage *)compressedImg{ unsigned char *pixels = [self getImagePixel:compressedImg]; int image_channels = 4; tensorflow::Tensor image_tensor( tensorflow::DT_FLOAT, tensorflow::TensorShape( {1, wanted_input_height, wanted_input_width, wanted_input_channels})); auto image_tensor_mapped = image_tensor.tensor&lt;float, 4&gt;(); tensorflow::uint8 *in = pixels; float *out = image_tensor_mapped.data(); for (int y = 0; y &lt; wanted_input_height; ++y) { float *out_row = out + (y * wanted_input_width * wanted_input_channels); for (int x = 0; x &lt; wanted_input_width; ++x) { tensorflow::uint8 *in_pixel = in + (x * wanted_input_width * image_channels) + (y * image_channels); float *out_pixel = out_row + (x * wanted_input_channels); for (int c = 0; c &lt; wanted_input_channels; ++c) { out_pixel[c] = in_pixel[c]; } } } tensorflow::Tensor style(tensorflow::DT_FLOAT, tensorflow::TensorShape({32})); float *style_data = style.tensor&lt;float, 1&gt;().data(); memset(style_data, 0, sizeof(float) * 32); style_data[currentStyle] = 1; if (tf_session.get()) { std::vector&lt;tensorflow::Tensor&gt; outputs; tensorflow::Status run_status = tf_session-&gt;Run( {{contentNode, image_tensor}, {styleNode, style}}, {outputNode}, {}, &amp;outputs); if (!run_status.ok()) { LOG(ERROR) &lt;&lt; &quot;Running model failed:&quot; &lt;&lt; run_status; isDone = true; free(pixels); } else { float *styledData = outputs[0].tensor&lt;float,4&gt;().data(); UIImage *styledImg = [self createImage:styledData]; dispatch_async(dispatch_get_main_queue(), ^{ _styleImageView.image = styledImg; dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(0.3 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{ isDone = true; free(pixels); }); }); } }}- (unsigned char *)getImagePixel:(UIImage *)image{ int width = image.size.width; int height = image.size.height; CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB(); unsigned char *rawData = (unsigned char*) calloc(height * width * 4, sizeof(unsigned char)); NSUInteger bytesPerPixel = 4; NSUInteger bytesPerRow = bytesPerPixel * width; NSUInteger bitsPerComponent = 8; CGContextRef context = CGBitmapContextCreate(rawData, width, height, bitsPerComponent, bytesPerRow, colorSpace, kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Big); CGColorSpaceRelease(colorSpace); CGContextDrawImage(context, CGRectMake(0, 0, width, height), image.CGImage); UIImage *ogImg = [UIImage imageWithCGImage:CGBitmapContextCreateImage(context)]; dispatch_async(dispatch_get_main_queue(), ^{ _ogImageView.image = ogImg; }); CGContextRelease(context); return rawData;}- (UIImage *)createImage:(float *)pixels{ unsigned char *rawData = (unsigned char*) calloc(wanted_input_height * wanted_input_width * 4, sizeof(unsigned char)); for (int y = 0; y &lt; wanted_input_height; ++y) { unsigned char *out_row = rawData + (y * wanted_input_width * 4); for (int x = 0; x &lt; wanted_input_width; ++x) { float *in_pixel = pixels + (x * wanted_input_width * 3) + (y * 3); unsigned char *out_pixel = out_row + (x * 4); for (int c = 0; c &lt; wanted_input_channels; ++c) { out_pixel[c] = in_pixel[c] * 255; } out_pixel[3] = UINT8_MAX; } } CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB(); NSUInteger bytesPerPixel = 4; NSUInteger bytesPerRow = bytesPerPixel * wanted_input_width; NSUInteger bitsPerComponent = 8; CGContextRef context = CGBitmapContextCreate(rawData, wanted_input_width, wanted_input_height, bitsPerComponent, bytesPerRow, colorSpace, kCGImageAlphaPremultipliedLast | kCGBitmapByteOrder32Big); CGColorSpaceRelease(colorSpace); UIImage *retImg = [UIImage imageWithCGImage:CGBitmapContextCreateImage(context)]; CGContextRelease(context); free(rawData); return retImg;} 这里说明一下，前面 python 工程已经定义了，我的输入和输出图片的大小是 512✕512。 连接 iPhone，运行工程^_^ 最后连上手机运行，就可以自己创建自己的艺术类图片了。😊 放几张运行效果图：","link":"/2017/04/28/iOS实现类Prisma软件/"}],"tags":[{"name":"小熊猫","slug":"小熊猫","link":"/tags/小熊猫/"},{"name":"新生","slug":"新生","link":"/tags/新生/"},{"name":"小程序","slug":"小程序","link":"/tags/小程序/"},{"name":"html","slug":"html","link":"/tags/html/"},{"name":"前端","slug":"前端","link":"/tags/前端/"},{"name":"移动端","slug":"移动端","link":"/tags/移动端/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"tensorflow","slug":"tensorflow","link":"/tags/tensorflow/"}],"categories":[{"name":"生活","slug":"生活","link":"/categories/生活/"},{"name":"小熊猫","slug":"生活/小熊猫","link":"/categories/生活/小熊猫/"},{"name":"工作","slug":"工作","link":"/categories/工作/"},{"name":"小程序","slug":"工作/小程序","link":"/categories/工作/小程序/"},{"name":"iOS","slug":"工作/iOS","link":"/categories/工作/iOS/"}]}